{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Training with ResNet50 from Scratch\n",
    "\n",
    "This notebook implements ImageNet training for ResNet50 from scratch, targeting 75% top-1 accuracy within a $25 budget.\n",
    "\n",
    "## Key Features:\n",
    "- ResNet50 implementation from scratch\n",
    "- Optimized for budget constraints\n",
    "- Mixed precision training\n",
    "- Data augmentation strategies\n",
    "- Model checkpointing and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install timm\n",
    "%pip install wandb\n",
    "%pip install accelerate\n",
    "%pip install transformers\n",
    "%pip install datasets\n",
    "%pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üöÄ EASY SWITCH: TESTING vs PRODUCTION MODE\n",
    "# =============================================================================\n",
    "# \n",
    "# TO RUN IN COLAB (TESTING MODE):\n",
    "#   1. Set TESTING_MODE = True\n",
    "#   2. Set PRODUCTION_MODE = False\n",
    "#\n",
    "# TO RUN IN PRODUCTION (IMAGENET):\n",
    "#   1. Set TESTING_MODE = False  \n",
    "#   2. Set PRODUCTION_MODE = True\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "# üß™ TESTING MODE (Colab/Development)\n",
    "TESTING_MODE = True\n",
    "PRODUCTION_MODE = False\n",
    "\n",
    "# üè≠ PRODUCTION MODE (ImageNet Training)\n",
    "# TESTING_MODE = False\n",
    "# PRODUCTION_MODE = True\n",
    "\n",
    "# =============================================================================\n",
    "# üöÄ QUANTIZATION OPTIONS FOR SPEED & BUDGET OPTIMIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# QUANTIZATION_MODE options:\n",
    "# - \"none\": No quantization (baseline)\n",
    "# - \"fp16\": Mixed precision (already enabled)\n",
    "# - \"int8\": 8-bit quantization (faster, smaller)\n",
    "# - \"dynamic\": Dynamic quantization (runtime)\n",
    "# - \"qat\": Quantization Aware Training (best accuracy)\n",
    "\n",
    "QUANTIZATION_MODE = \"fp16\"  # Change this to experiment with different quantization\n",
    "\n",
    "# Advanced quantization settings\n",
    "QUANTIZATION_CONFIG = {\n",
    "    \"fp16\": {\n",
    "        \"description\": \"Mixed Precision (FP16) - 2x speed, 50% memory\",\n",
    "        \"speed_boost\": \"2x\",\n",
    "        \"memory_saving\": \"50%\",\n",
    "        \"accuracy_loss\": \"0-1%\",\n",
    "        \"cost_reduction\": \"30-40%\"\n",
    "    },\n",
    "    \"int8\": {\n",
    "        \"description\": \"8-bit Quantization - 3x speed, 75% memory\",\n",
    "        \"speed_boost\": \"3x\", \n",
    "        \"memory_saving\": \"75%\",\n",
    "        \"accuracy_loss\": \"1-3%\",\n",
    "        \"cost_reduction\": \"50-60%\"\n",
    "    },\n",
    "    \"dynamic\": {\n",
    "        \"description\": \"Dynamic Quantization - 2.5x speed, 60% memory\",\n",
    "        \"speed_boost\": \"2.5x\",\n",
    "        \"memory_saving\": \"60%\", \n",
    "        \"accuracy_loss\": \"0.5-2%\",\n",
    "        \"cost_reduction\": \"40-50%\"\n",
    "    },\n",
    "    \"qat\": {\n",
    "        \"description\": \"Quantization Aware Training - 2.5x speed, 60% memory\",\n",
    "        \"speed_boost\": \"2.5x\",\n",
    "        \"memory_saving\": \"60%\",\n",
    "        \"accuracy_loss\": \"0-1%\",\n",
    "        \"cost_reduction\": \"40-50%\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# üìä CONFIGURATION BASED ON MODE\n",
    "# =============================================================================\n",
    "\n",
    "if TESTING_MODE:\n",
    "    print(\"üß™ RUNNING IN TESTING MODE (CIFAR-100)\")\n",
    "    print(\"   - Dataset: CIFAR-100 (100 classes)\")\n",
    "    print(\"   - Epochs: 5 (reduced for testing)\")\n",
    "    print(\"   - Batch Size: 16 (memory efficient)\")\n",
    "    print(\"   - Target Accuracy: 80%\")\n",
    "    print(\"   - Wandb: Disabled\")\n",
    "    \n",
    "elif PRODUCTION_MODE:\n",
    "    print(\"üè≠ RUNNING IN PRODUCTION MODE (ImageNet-1K)\")\n",
    "    print(\"   - Dataset: ImageNet-1K (1000 classes)\")\n",
    "    print(\"   - Epochs: 90 (full training)\")\n",
    "    print(\"   - Batch Size: 64 (optimized)\")\n",
    "    print(\"   - Target Accuracy: 75%\")\n",
    "    print(\"   - Wandb: Enabled\")\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"Please set either TESTING_MODE=True or PRODUCTION_MODE=True\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üîß QUANTIZATION IMPLEMENTATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "import torch.quantization as quant\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "def apply_quantization(model, quantization_mode, device):\n",
    "    \"\"\"\n",
    "    Apply different quantization strategies to the model\n",
    "    \"\"\"\n",
    "    print(f\"üîß Applying {quantization_mode} quantization...\")\n",
    "    \n",
    "    if quantization_mode == \"none\":\n",
    "        print(\"   ‚Üí No quantization applied (baseline)\")\n",
    "        return model\n",
    "        \n",
    "    elif quantization_mode == \"fp16\":\n",
    "        print(\"   ‚Üí Using mixed precision (FP16) - 2x speed boost\")\n",
    "        # Mixed precision is handled by Accelerator\n",
    "        return model\n",
    "        \n",
    "    elif quantization_mode == \"int8\":\n",
    "        print(\"   ‚Üí Applying 8-bit quantization - 3x speed boost\")\n",
    "        # Set model to evaluation mode for quantization\n",
    "        model.eval()\n",
    "        \n",
    "        # Configure quantization\n",
    "        model.qconfig = quant.get_default_qconfig('fbgemm')\n",
    "        \n",
    "        # Prepare model for quantization\n",
    "        model_prepared = quant.prepare(model)\n",
    "        \n",
    "        # Calibrate with dummy data (in practice, use real data)\n",
    "        dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "        with torch.no_grad():\n",
    "            model_prepared(dummy_input)\n",
    "        \n",
    "        # Convert to quantized model\n",
    "        model_quantized = quant.convert(model_prepared)\n",
    "        print(\"   ‚Üí Model quantized to INT8\")\n",
    "        return model_quantized\n",
    "        \n",
    "    elif quantization_mode == \"dynamic\":\n",
    "        print(\"   ‚Üí Applying dynamic quantization - 2.5x speed boost\")\n",
    "        # Dynamic quantization (weights quantized, activations in FP32)\n",
    "        model_quantized = quant.quantize_dynamic(\n",
    "            model, \n",
    "            {torch.nn.Linear, torch.nn.Conv2d}, \n",
    "            dtype=torch.qint8\n",
    "        )\n",
    "        print(\"   ‚Üí Model dynamically quantized\")\n",
    "        return model_quantized\n",
    "        \n",
    "    elif quantization_mode == \"qat\":\n",
    "        print(\"   ‚Üí Setting up Quantization Aware Training - 2.5x speed boost\")\n",
    "        # QAT requires special setup - we'll configure it for training\n",
    "        model.qconfig = quant.get_default_qat_qconfig('fbgemm')\n",
    "        model_prepared = quant.prepare_qat(model)\n",
    "        print(\"   ‚Üí Model prepared for QAT\")\n",
    "        return model_prepared\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown quantization mode: {quantization_mode}\")\n",
    "\n",
    "def get_quantization_info(model, quantization_mode):\n",
    "    \"\"\"\n",
    "    Get information about model size and performance with quantization\n",
    "    \"\"\"\n",
    "    if quantization_mode == \"none\":\n",
    "        return {\n",
    "            \"model_size_mb\": sum(p.numel() for p in model.parameters()) * 4 / 1e6,\n",
    "            \"parameters\": sum(p.numel() for p in model.parameters()),\n",
    "            \"speed_boost\": \"1x\",\n",
    "            \"memory_saving\": \"0%\"\n",
    "        }\n",
    "    \n",
    "    # Calculate quantized model size\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    if quantization_mode == \"fp16\":\n",
    "        model_size = total_params * 2 / 1e6  # 2 bytes per parameter\n",
    "        return {\n",
    "            \"model_size_mb\": model_size,\n",
    "            \"parameters\": total_params,\n",
    "            \"speed_boost\": \"2x\",\n",
    "            \"memory_saving\": \"50%\"\n",
    "        }\n",
    "    elif quantization_mode in [\"int8\", \"dynamic\", \"qat\"]:\n",
    "        model_size = total_params * 1 / 1e6  # 1 byte per parameter\n",
    "        return {\n",
    "            \"model_size_mb\": model_size,\n",
    "            \"parameters\": total_params,\n",
    "            \"speed_boost\": \"3x\" if quantization_mode == \"int8\" else \"2.5x\",\n",
    "            \"memory_saving\": \"75%\" if quantization_mode == \"int8\" else \"60%\"\n",
    "        }\n",
    "\n",
    "def print_quantization_summary(quantization_mode, config_info):\n",
    "    \"\"\"\n",
    "    Print a summary of quantization benefits\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üöÄ QUANTIZATION BENEFITS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if quantization_mode in QUANTIZATION_CONFIG:\n",
    "        info = QUANTIZATION_CONFIG[quantization_mode]\n",
    "        print(f\"Mode: {quantization_mode.upper()}\")\n",
    "        print(f\"Description: {info['description']}\")\n",
    "        print(f\"Speed Boost: {info['speed_boost']}\")\n",
    "        print(f\"Memory Saving: {info['memory_saving']}\")\n",
    "        print(f\"Accuracy Loss: {info['accuracy_loss']}\")\n",
    "        print(f\"Cost Reduction: {info['cost_reduction']}\")\n",
    "        \n",
    "        # Calculate new training time and cost\n",
    "        if PRODUCTION_MODE:\n",
    "            base_time = 12  # hours\n",
    "            base_cost = 15   # dollars\n",
    "            \n",
    "            speed_multiplier = float(info['speed_boost'].replace('x', ''))\n",
    "            cost_reduction = float(info['cost_reduction'].split('-')[0]) / 100\n",
    "            \n",
    "            new_time = base_time / speed_multiplier\n",
    "            new_cost = base_cost * (1 - cost_reduction)\n",
    "            \n",
    "            print(f\"\\nüí∞ BUDGET IMPACT:\")\n",
    "            print(f\"   Original Time: {base_time}h ‚Üí {new_time:.1f}h\")\n",
    "            print(f\"   Original Cost: ${base_cost} ‚Üí ${new_cost:.1f}\")\n",
    "            print(f\"   Savings: ${base_cost - new_cost:.1f} ({info['cost_reduction']})\")\n",
    "    \n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageNet\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import wandb\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import warnings\n",
    "import logging\n",
    "import psutil\n",
    "import gc\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "\n",
    "# =============================================================================\n",
    "# üìä COMPREHENSIVE LOGGING AND MONITORING SYSTEM\n",
    "# =============================================================================\n",
    "\n",
    "class TrainingMonitor:\n",
    "    \"\"\"\n",
    "    Comprehensive training monitoring and logging system\n",
    "    \"\"\"\n",
    "    def __init__(self, log_dir='logs', enable_wandb=False):\n",
    "        self.log_dir = log_dir\n",
    "        self.enable_wandb = enable_wandb\n",
    "        self.start_time = time.time()\n",
    "        self.epoch_times = []\n",
    "        self.memory_usage = []\n",
    "        self.gpu_memory_usage = []\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "        self.learning_rates = []\n",
    "        \n",
    "        # Setup logging\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        self.setup_logging()\n",
    "        \n",
    "        # Initialize monitoring\n",
    "        self.log_system_info()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Setup comprehensive logging system\"\"\"\n",
    "        log_file = os.path.join(self.log_dir, f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.info(\"üöÄ Training monitoring system initialized\")\n",
    "        \n",
    "    def log_system_info(self):\n",
    "        \"\"\"Log system information\"\"\"\n",
    "        self.logger.info(\"=\" * 60)\n",
    "        self.logger.info(\"üñ•Ô∏è SYSTEM INFORMATION\")\n",
    "        self.logger.info(\"=\" * 60)\n",
    "        self.logger.info(f\"Device: {device}\")\n",
    "        self.logger.info(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            self.logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "            self.logger.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        \n",
    "        self.logger.info(f\"PyTorch Version: {torch.__version__}\")\n",
    "        self.logger.info(f\"CPU Count: {psutil.cpu_count()}\")\n",
    "        self.logger.info(f\"RAM: {psutil.virtual_memory().total / 1e9:.1f} GB\")\n",
    "        self.logger.info(\"=\" * 60)\n",
    "        \n",
    "    def log_epoch_start(self, epoch, total_epochs):\n",
    "        \"\"\"Log epoch start information\"\"\"\n",
    "        self.logger.info(f\"üöÄ Starting Epoch {epoch}/{total_epochs}\")\n",
    "        self.logger.info(f\"   Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "    def log_epoch_end(self, epoch, train_loss, train_acc, val_loss, val_acc, lr, epoch_time):\n",
    "        \"\"\"Log epoch end information\"\"\"\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        self.losses.append({'train': train_loss, 'val': val_loss})\n",
    "        self.accuracies.append({'train': train_acc, 'val': val_acc})\n",
    "        self.learning_rates.append(lr)\n",
    "        \n",
    "        # Log epoch summary\n",
    "        self.logger.info(f\"‚úÖ Epoch {epoch} completed in {epoch_time:.2f}s\")\n",
    "        self.logger.info(f\"   Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        self.logger.info(f\"   Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        self.logger.info(f\"   Learning Rate: {lr:.6f}\")\n",
    "        \n",
    "        # Log resource usage\n",
    "        self.log_resource_usage()\n",
    "        \n",
    "    def log_resource_usage(self):\n",
    "        \"\"\"Log current resource usage\"\"\"\n",
    "        # CPU and RAM usage\n",
    "        cpu_percent = psutil.cpu_percent()\n",
    "        ram = psutil.virtual_memory()\n",
    "        ram_percent = ram.percent\n",
    "        ram_used_gb = ram.used / 1e9\n",
    "        \n",
    "        self.logger.info(f\"üìä Resource Usage:\")\n",
    "        self.logger.info(f\"   CPU: {cpu_percent:.1f}%\")\n",
    "        self.logger.info(f\"   RAM: {ram_percent:.1f}% ({ram_used_gb:.1f} GB used)\")\n",
    "        \n",
    "        # GPU usage\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory = torch.cuda.memory_allocated() / 1e9\n",
    "            gpu_memory_max = torch.cuda.max_memory_allocated() / 1e9\n",
    "            gpu_utilization = torch.cuda.utilization() if hasattr(torch.cuda, 'utilization') else 0\n",
    "            \n",
    "            self.logger.info(f\"   GPU Memory: {gpu_memory:.1f} GB (Peak: {gpu_memory_max:.1f} GB)\")\n",
    "            if gpu_utilization > 0:\n",
    "                self.logger.info(f\"   GPU Utilization: {gpu_utilization:.1f}%\")\n",
    "        \n",
    "        # Store for tracking\n",
    "        self.memory_usage.append({\n",
    "            'cpu_percent': cpu_percent,\n",
    "            'ram_percent': ram_percent,\n",
    "            'ram_used_gb': ram_used_gb,\n",
    "            'gpu_memory_gb': gpu_memory if torch.cuda.is_available() else 0\n",
    "        })\n",
    "        \n",
    "    def log_training_complete(self, best_accuracy, total_time):\n",
    "        \"\"\"Log training completion\"\"\"\n",
    "        self.logger.info(\"=\" * 60)\n",
    "        self.logger.info(\"üéâ TRAINING COMPLETED\")\n",
    "        self.logger.info(\"=\" * 60)\n",
    "        self.logger.info(f\"Total Time: {total_time/3600:.2f} hours\")\n",
    "        self.logger.info(f\"Best Accuracy: {best_accuracy:.2f}%\")\n",
    "        self.logger.info(f\"Average Epoch Time: {np.mean(self.epoch_times):.2f}s\")\n",
    "        self.logger.info(f\"Total Epochs: {len(self.epoch_times)}\")\n",
    "        \n",
    "        # Log final resource usage\n",
    "        self.log_resource_usage()\n",
    "        \n",
    "        # Save training summary\n",
    "        self.save_training_summary(best_accuracy, total_time)\n",
    "        \n",
    "    def save_training_summary(self, best_accuracy, total_time):\n",
    "        \"\"\"Save comprehensive training summary\"\"\"\n",
    "        summary = {\n",
    "            'training_info': {\n",
    "                'start_time': self.start_time,\n",
    "                'total_time_hours': total_time / 3600,\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'total_epochs': len(self.epoch_times),\n",
    "                'average_epoch_time': np.mean(self.epoch_times)\n",
    "            },\n",
    "            'performance_metrics': {\n",
    "                'losses': self.losses,\n",
    "                'accuracies': self.accuracies,\n",
    "                'learning_rates': self.learning_rates,\n",
    "                'epoch_times': self.epoch_times\n",
    "            },\n",
    "            'resource_usage': self.memory_usage,\n",
    "            'system_info': {\n",
    "                'device': str(device),\n",
    "                'cuda_available': torch.cuda.is_available(),\n",
    "                'pytorch_version': torch.__version__\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        summary_file = os.path.join(self.log_dir, 'training_summary.json')\n",
    "        with open(summary_file, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        self.logger.info(f\"üìÑ Training summary saved to: {summary_file}\")\n",
    "\n",
    "# NOTE: The TrainingMonitor is defined here, but instantiated after the config is created.\n",
    "\n",
    "# =============================================================================\n",
    "# üõë EARLY STOPPING MECHANISM\n",
    "# =============================================================================\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping mechanism to prevent overfitting and save resources\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.001, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_score, model):\n",
    "        \"\"\"\n",
    "        Check if training should stop early\n",
    "        Returns: True if training should stop, False otherwise\n",
    "        \"\"\"\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_weights)\n",
    "                return True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Save model weights\"\"\"\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "# NOTE: early_stopping instance will be created after the config is defined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 Implementation from Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        \n",
    "        # FIXED: Modified for CIFAR-100 (32x32 images) vs ImageNet (224x224)\n",
    "        if num_classes == 100:  # CIFAR-100\n",
    "            # Smaller initial conv for CIFAR-100\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            self.maxpool = nn.Identity()  # No maxpool for CIFAR-100\n",
    "        else:  # ImageNet\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)  # Identity for CIFAR-100, MaxPool for ImageNet\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def ResNet50(num_classes=1000):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes)\n",
    "\n",
    "def ResNet18(num_classes=1000):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
    "\n",
    "def ResNet34(num_classes=1000):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n",
    "\n",
    "# Test the model\n",
    "model = ResNet50()\n",
    "print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "print(f'Model size: {sum(p.numel() for p in model.parameters()) * 4 / 1e6:.1f} MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and preprocessing\n",
    "def get_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.08, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# For Colab testing, we'll use CIFAR-100 as a smaller dataset\n",
    "# In production, replace with ImageNet\n",
    "def get_cifar100_dataset():\n",
    "    # FIXED: Proper transforms for CIFAR-100 (32x32 images)\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])  # CIFAR-100 stats\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])  # CIFAR-100 stats\n",
    "    ])\n",
    "    \n",
    "    # Use CIFAR-100 for testing (100 classes, similar to ImageNet structure)\n",
    "    train_dataset = torchvision.datasets.CIFAR100(\n",
    "        root='./data', train=True, download=True, transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = torchvision.datasets.CIFAR100(\n",
    "        root='./data', train=False, download=True, transform=val_transform\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# For ImageNet (use this in production)\n",
    "def get_imagenet_dataset(data_path):\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    # Try torchvision ImageNet first; fallback to ImageFolder if index not found\n",
    "    try:\n",
    "        train_dataset = ImageNet(\n",
    "            root=data_path, split='train', transform=train_transform\n",
    "        )\n",
    "        val_dataset = ImageNet(\n",
    "            root=data_path, split='val', transform=val_transform\n",
    "        )\n",
    "        print(\"‚úÖ Loaded torchvision.datasets.ImageNet\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è torchvision.datasets.ImageNet failed: {e}\")\n",
    "        print(\"   Falling back to torchvision.datasets.ImageFolder (expects class subfolders)...\")\n",
    "        from torchvision.datasets import ImageFolder\n",
    "        train_dataset = ImageFolder(\n",
    "            root=os.path.join(data_path, 'train'), transform=train_transform\n",
    "        )\n",
    "        val_dataset = ImageFolder(\n",
    "            root=os.path.join(data_path, 'val'), transform=val_transform\n",
    "        )\n",
    "        print(\"‚úÖ Loaded torchvision.datasets.ImageFolder\")\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# =============================================================================\n",
    "# üìÅ DATASET LOADING WITH VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "def validate_dataset(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Comprehensive dataset validation\n",
    "    \"\"\"\n",
    "    print(f\"üîç Validating {dataset_name} dataset...\")\n",
    "    \n",
    "    # Check dataset size\n",
    "    if len(dataset) == 0:\n",
    "        raise ValueError(f\"{dataset_name} dataset is empty!\")\n",
    "    \n",
    "    # Check for corrupted samples\n",
    "    corrupted_samples = 0\n",
    "    valid_samples = 0\n",
    "    \n",
    "    for i in range(min(100, len(dataset))):  # Check first 100 samples\n",
    "        try:\n",
    "            data, target = dataset[i]\n",
    "            if torch.isnan(data).any() or torch.isinf(data).any():\n",
    "                corrupted_samples += 1\n",
    "            else:\n",
    "                valid_samples += 1\n",
    "        except Exception as e:\n",
    "            corrupted_samples += 1\n",
    "    \n",
    "    print(f\"   Dataset size: {len(dataset)}\")\n",
    "    print(f\"   Valid samples (checked): {valid_samples}\")\n",
    "    print(f\"   Corrupted samples: {corrupted_samples}\")\n",
    "    \n",
    "    if corrupted_samples > len(dataset) * 0.1:  # More than 10% corrupted\n",
    "        print(f\"‚ö†Ô∏è WARNING: High corruption rate in {dataset_name} ({corrupted_samples/len(dataset)*100:.1f}%)\")\n",
    "    \n",
    "    return valid_samples > 0\n",
    "\n",
    "if TESTING_MODE:\n",
    "    # üß™ TESTING: Use CIFAR-100 (smaller dataset for Colab)\n",
    "    print(\"Loading CIFAR-100 dataset for testing...\")\n",
    "    train_dataset, val_dataset = get_cifar100_dataset()\n",
    "    batch_size = 16  # Smaller batch for Colab memory\n",
    "    num_workers = 2  # Fewer workers for Colab\n",
    "    print(f\"‚úÖ CIFAR-100 loaded: {len(train_dataset)} train, {len(val_dataset)} val samples\")\n",
    "    print(f\"‚úÖ Number of classes: {len(train_dataset.classes)}\")\n",
    "    \n",
    "    # Validate datasets\n",
    "    validate_dataset(train_dataset, \"CIFAR-100 Train\")\n",
    "    validate_dataset(val_dataset, \"CIFAR-100 Val\")\n",
    "    \n",
    "elif PRODUCTION_MODE:\n",
    "    # üè≠ PRODUCTION: Use ImageNet-1K (full dataset)\n",
    "    print(\"Loading ImageNet-1K dataset for production...\")\n",
    "    train_dataset, val_dataset = get_imagenet_dataset('./imagenet/')\n",
    "    batch_size = 64  # Larger batch for production\n",
    "    num_workers = 8  # More workers for production\n",
    "    print(f\"‚úÖ ImageNet-1K loaded: {len(train_dataset)} train, {len(val_dataset)} val samples\")\n",
    "    print(f\"‚úÖ Number of classes: {len(train_dataset.classes)}\")\n",
    "    \n",
    "    # Validate datasets\n",
    "    validate_dataset(train_dataset, \"ImageNet Train\")\n",
    "    validate_dataset(val_dataset, \"ImageNet Val\")\n",
    "\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of workers: {num_workers}\")\n",
    "\n",
    "# Create data loaders with error handling\n",
    "try:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, \n",
    "        num_workers=num_workers, pin_memory=True, \n",
    "        persistent_workers=True if num_workers > 0 else False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, \n",
    "        num_workers=num_workers, pin_memory=True,\n",
    "        persistent_workers=True if num_workers > 0 else False\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Data loaders created successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è WARNING: Error creating data loaders: {e}\")\n",
    "    print(\"   Falling back to single-threaded loading...\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, \n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, \n",
    "        num_workers=0, pin_memory=False\n",
    "    )\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n",
    "print(f'Number of classes: {len(train_dataset.classes)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration and Optimizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ‚öôÔ∏è TRAINING CONFIGURATION BASED ON MODE\n",
    "# =============================================================================\n",
    "\n",
    "if TESTING_MODE:\n",
    "    # üß™ TESTING CONFIGURATION (Colab-friendly)\n",
    "    config = {\n",
    "        'epochs': 5,  # Reduced for quick testing\n",
    "        'learning_rate': 0.05,  # FIXED: Proper learning rate for CIFAR-100 (0.1 was too high!)\n",
    "        'weight_decay': 1e-4,\n",
    "        'momentum': 0.9,\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': len(train_dataset.classes),\n",
    "        'save_every': 2,  # Save more frequently for testing\n",
    "        'eval_every': 1,  # Evaluate every epoch\n",
    "        'mixed_precision': QUANTIZATION_MODE == \"fp16\",  # Enable based on quantization\n",
    "        'gradient_accumulation_steps': 1,\n",
    "        'warmup_epochs': 0,  # FIXED: No warmup for CIFAR-100 (causes issues)\n",
    "        'cosine_annealing': True,\n",
    "        'target_accuracy': 80.0,  # Higher target for CIFAR-100\n",
    "        'wandb_enabled': False,  # Disable wandb for testing\n",
    "        'quantization_mode': QUANTIZATION_MODE,  # Add quantization mode\n",
    "        'quantization_enabled': QUANTIZATION_MODE != \"none\",\n",
    "        'torch_compile': True,  # Enable torch.compile optimization\n",
    "        'compile_mode': 'default',  # 'default', 'reduce-overhead', 'max-autotune'\n",
    "        # Enhanced monitoring and error handling\n",
    "        'early_stopping_patience': 3,  # Early stopping for testing\n",
    "        'early_stopping_min_delta': 0.001,  # Minimum improvement threshold\n",
    "        'gradient_clip_norm': 1.0,  # Gradient clipping\n",
    "        'memory_cleanup_frequency': 5  # Memory cleanup every N epochs\n",
    "    }\n",
    "    \n",
    "elif PRODUCTION_MODE:\n",
    "    # üè≠ PRODUCTION CONFIGURATION (Full ImageNet training)\n",
    "    config = {\n",
    "        'epochs': 90,  # Full training\n",
    "        'learning_rate': 0.1,  # Standard for ImageNet with proper scheduling\n",
    "        'weight_decay': 1e-4,\n",
    "        'momentum': 0.9,\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': len(train_dataset.classes),\n",
    "        'save_every': 10,  # Save every 10 epochs\n",
    "        'eval_every': 5,  # Evaluate every 5 epochs\n",
    "        'mixed_precision': QUANTIZATION_MODE == \"fp16\",  # Enable based on quantization\n",
    "        'gradient_accumulation_steps': 1,\n",
    "        'warmup_epochs': 5,  # Full warmup\n",
    "        'cosine_annealing': True,\n",
    "        'target_accuracy': 75.0,  # ImageNet target\n",
    "        'wandb_enabled': True,  # Enable wandb for production\n",
    "        'quantization_mode': QUANTIZATION_MODE,  # Add quantization mode\n",
    "        'quantization_enabled': QUANTIZATION_MODE != \"none\",\n",
    "        'torch_compile': True,  # Enable torch.compile optimization\n",
    "        'compile_mode': 'default',  # 'default', 'reduce-overhead', 'max-autotune'\n",
    "        # Enhanced monitoring and error handling\n",
    "        'early_stopping_patience': 10,  # Early stopping for production\n",
    "        'early_stopping_min_delta': 0.001,  # Minimum improvement threshold\n",
    "        'gradient_clip_norm': 1.0,  # Gradient clipping\n",
    "        'memory_cleanup_frequency': 10  # Memory cleanup every N epochs\n",
    "    }\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Initialize model for the correct number of classes\n",
    "# FIXED: Use ResNet18 for CIFAR-100 (ResNet50 is too deep for 32x32 images)\n",
    "if TESTING_MODE:\n",
    "    model = ResNet18(num_classes=config['num_classes'])  # ResNet18 for CIFAR-100\n",
    "    print(\"üèóÔ∏è Using ResNet18 for CIFAR-100 (32x32 images)\")\n",
    "else:\n",
    "    model = ResNet50(num_classes=config['num_classes'])  # ResNet50 for ImageNet\n",
    "    print(\"üèóÔ∏è Using ResNet50 for ImageNet (224x224 images)\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# FIXED: Proper initialization for CIFAR-100\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# Apply proper initialization\n",
    "model.apply(init_weights)\n",
    "print(f\"‚úÖ Model initialized with proper weights for {config['num_classes']} classes\")\n",
    "\n",
    "# DEBUG: Test model with a sample batch\n",
    "print(\"\\nüîç DEBUG - Testing model with sample batch...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_data, sample_target = next(iter(train_loader))\n",
    "    sample_data = sample_data[:4].to(device)  # FIXED: Move to same device as model\n",
    "    sample_target = sample_target[:4].to(device)  # FIXED: Move to same device as model\n",
    "    \n",
    "    print(f\"   Input shape: {sample_data.shape}\")\n",
    "    print(f\"   Target shape: {sample_target.shape}\")\n",
    "    print(f\"   Target values: {sample_target.tolist()}\")\n",
    "    print(f\"   Device: {sample_data.device} (model: {next(model.parameters()).device})\")\n",
    "    \n",
    "    sample_output = model(sample_data)\n",
    "    print(f\"   Output shape: {sample_output.shape}\")\n",
    "    print(f\"   Output range: [{sample_output.min().item():.3f}, {sample_output.max().item():.3f}]\")\n",
    "    \n",
    "    sample_pred = sample_output.argmax(dim=1)\n",
    "    print(f\"   Predictions: {sample_pred.tolist()}\")\n",
    "    \n",
    "    sample_acc = (sample_pred == sample_target).float().mean().item()\n",
    "    print(f\"   Sample accuracy: {sample_acc:.2f}%\")\n",
    "    \n",
    "    # Check if model is learning (outputs should be reasonable)\n",
    "    if sample_output.std().item() < 0.1:\n",
    "        print(\"‚ö†Ô∏è WARNING: Model outputs have very low variance - may indicate initialization issues\")\n",
    "    else:\n",
    "        print(\"‚úÖ Model outputs have reasonable variance\")\n",
    "\n",
    "model.train()  # Set back to training mode\n",
    "\n",
    "# =============================================================================\n",
    "# üîç VERIFY MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüîç Model Configuration Verification:\")\n",
    "print(f\"   Dataset: {'CIFAR-100' if TESTING_MODE else 'ImageNet-1K'}\")\n",
    "print(f\"   Number of classes: {config['num_classes']}\")\n",
    "print(f\"   Model output size: {model.fc.out_features}\")\n",
    "print(f\"   Target accuracy: {config['target_accuracy']}%\")\n",
    "print(f\"   Learning rate: {config['learning_rate']}\")\n",
    "\n",
    "# Verify model output matches dataset classes\n",
    "if model.fc.out_features == config['num_classes']:\n",
    "    print(\"‚úÖ Model output size matches dataset classes\")\n",
    "else:\n",
    "    print(f\"‚ùå MISMATCH: Model outputs {model.fc.out_features} classes, dataset has {config['num_classes']} classes\")\n",
    "\n",
    "# =============================================================================\n",
    "# üöÄ TORCH.COMPILE OPTIMIZATION (10% speed boost)\n",
    "# =============================================================================\n",
    "\n",
    "# Apply torch.compile for 10% speed boost (PyTorch 2.0+)\n",
    "if config.get('torch_compile', False):\n",
    "    if hasattr(torch, 'compile'):\n",
    "        try:\n",
    "            compile_mode = config.get('compile_mode', 'default')\n",
    "            print(f\"üöÄ Applying torch.compile() optimization with mode: {compile_mode}\")\n",
    "            print(\"   Note: First few iterations will be slower due to compilation...\")\n",
    "            model = torch.compile(model, mode=compile_mode)\n",
    "            print(\"‚úÖ Model compiled successfully! Expected 10% speed boost.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è torch.compile() failed: {e}\")\n",
    "            print(\"   Continuing without compilation...\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è torch.compile() not available (requires PyTorch 2.0+)\")\n",
    "        print(\"   Continuing without compilation...\")\n",
    "else:\n",
    "    print(\"üìä torch.compile() disabled in configuration\")\n",
    "\n",
    "# Initialize accelerator for mixed precision training\n",
    "accelerator = Accelerator(mixed_precision='fp16' if config['mixed_precision'] else 'no')\n",
    "\n",
    "# Optimizer with learning rate scheduling\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=config['learning_rate'], \n",
    "    momentum=config['momentum'], \n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "def get_lr_scheduler(optimizer, num_epochs, warmup_epochs=5):\n",
    "    def lr_lambda(epoch):\n",
    "        if warmup_epochs == 0:\n",
    "            # No warmup - use cosine annealing directly\n",
    "            return 0.5 * (1 + math.cos(math.pi * epoch / num_epochs))\n",
    "        elif epoch < warmup_epochs:\n",
    "            return epoch / warmup_epochs\n",
    "        else:\n",
    "            return 0.5 * (1 + math.cos(math.pi * (epoch - warmup_epochs) / (num_epochs - warmup_epochs)))\n",
    "    \n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "scheduler = get_lr_scheduler(optimizer, config['epochs'], config['warmup_epochs'])\n",
    "\n",
    "# Loss function\n",
    "# FIXED: Reduce label smoothing for CIFAR-100 (0.1 is too high for small dataset)\n",
    "if TESTING_MODE:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.0)  # No label smoothing for CIFAR-100\n",
    "    print(\"üéØ Using CrossEntropyLoss without label smoothing for CIFAR-100\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing for ImageNet\n",
    "    print(\"üéØ Using CrossEntropyLoss with label smoothing for ImageNet\")\n",
    "\n",
    "# Prepare for accelerator\n",
    "model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_loader, val_loader, scheduler\n",
    ")\n",
    "\n",
    "# Instantiate monitoring and early stopping now that config exists\n",
    "monitor = TrainingMonitor(log_dir='logs', enable_wandb=config.get('wandb_enabled', False))\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=config.get('early_stopping_patience', 10),\n",
    "    min_delta=config.get('early_stopping_min_delta', 0.001),\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(f\"Model prepared for training on {device}\")\n",
    "print(f\"Mixed precision: {config['mixed_precision']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üöÄ APPLY QUANTIZATION FOR SPEED & BUDGET OPTIMIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# Apply quantization if enabled\n",
    "if config['quantization_enabled']:\n",
    "    print(f\"\\nüîß Applying {config['quantization_mode']} quantization...\")\n",
    "    model = apply_quantization(model, config['quantization_mode'], device)\n",
    "    \n",
    "    # Print quantization benefits\n",
    "    quant_info = get_quantization_info(model, config['quantization_mode'])\n",
    "    print(f\"\\nüìä Model Info with {config['quantization_mode']} quantization:\")\n",
    "    print(f\"   Model Size: {quant_info['model_size_mb']:.1f} MB\")\n",
    "    print(f\"   Parameters: {quant_info['parameters']:,}\")\n",
    "    print(f\"   Speed Boost: {quant_info['speed_boost']}\")\n",
    "    print(f\"   Memory Saving: {quant_info['memory_saving']}\")\n",
    "    \n",
    "    # Print budget impact for production\n",
    "    if PRODUCTION_MODE:\n",
    "        print_quantization_summary(config['quantization_mode'], quant_info)\n",
    "else:\n",
    "    print(\"üìä No quantization applied - using full precision\")\n",
    "    print(f\"   Model Size: {sum(p.numel() for p in model.parameters()) * 4 / 1e6:.1f} MB\")\n",
    "    print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, accelerator, epoch):\n",
    "    \"\"\"\n",
    "    Enhanced training epoch with comprehensive error handling and monitoring\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    failed_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        try:\n",
    "            # FIXED: Ensure data and target are on the same device as model\n",
    "            data = data.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "            \n",
    "            # Data validation\n",
    "            if data.isnan().any() or target.isnan().any():\n",
    "                print(f\"‚ö†Ô∏è WARNING: NaN detected in batch {batch_idx}, skipping...\")\n",
    "                failed_batches += 1\n",
    "                continue\n",
    "                \n",
    "            if data.isinf().any() or target.isinf().any():\n",
    "                print(f\"‚ö†Ô∏è WARNING: Inf detected in batch {batch_idx}, skipping...\")\n",
    "                failed_batches += 1\n",
    "                continue\n",
    "            \n",
    "            with accelerator.accumulate(model):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                # Check for NaN loss\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"‚ö†Ô∏è WARNING: Invalid loss detected in batch {batch_idx}, skipping...\")\n",
    "                    failed_batches += 1\n",
    "                    continue\n",
    "                \n",
    "                accelerator.backward(loss)\n",
    "                \n",
    "                # Gradient clipping to prevent exploding gradients\n",
    "                if hasattr(accelerator, 'clip_grad_norm_'):\n",
    "                    accelerator.clip_grad_norm_(\n",
    "                        model.parameters(), max_norm=config.get('gradient_clip_norm', 1.0)\n",
    "                    )\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                total += target.size(0)\n",
    "                \n",
    "                # DEBUG: Print first batch accuracy for verification\n",
    "                if batch_idx == 0:\n",
    "                    batch_acc = 100. * pred.eq(target.view_as(pred)).sum().item() / target.size(0)\n",
    "                    print(f\"\\nüîç DEBUG - First batch accuracy: {batch_acc:.2f}%\")\n",
    "                    print(f\"   Batch size: {target.size(0)}\")\n",
    "                    print(f\"   Correct predictions: {pred.eq(target.view_as(pred)).sum().item()}\")\n",
    "                    print(f\"   Sample predictions: {pred[:5].flatten().tolist()}\")\n",
    "                    print(f\"   Sample targets: {target[:5].tolist()}\")\n",
    "                    print(f\"   Device check: data={data.device}, target={target.device}, model={next(model.parameters()).device}\")\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{100. * correct / total:.2f}%',\n",
    "                    'LR': f'{optimizer.param_groups[0][\"lr\"]:.6f}',\n",
    "                    'Failed': f'{failed_batches}'\n",
    "                })\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "                print(f\"üö® CUDA OOM ERROR in batch {batch_idx}: {e}\")\n",
    "                print(\"   Attempting recovery...\")\n",
    "                \n",
    "                # Clear cache and try again with smaller batch\n",
    "                torch.cuda.empty_cache()\n",
    "                if hasattr(torch.cuda, 'reset_peak_memory_stats'):\n",
    "                    torch.cuda.reset_peak_memory_stats()\n",
    "                \n",
    "                # Reduce batch size for next iteration\n",
    "                if batch_size > 1:\n",
    "                    print(f\"   Reducing batch size from {batch_size} to {max(1, batch_size // 2)}\")\n",
    "                    # Note: This would require recreating the dataloader\n",
    "                \n",
    "                failed_batches += 1\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"üö® RUNTIME ERROR in batch {batch_idx}: {e}\")\n",
    "                failed_batches += 1\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"üö® UNEXPECTED ERROR in batch {batch_idx}: {e}\")\n",
    "            failed_batches += 1\n",
    "            continue\n",
    "    \n",
    "    # Report failed batches\n",
    "    if failed_batches > 0:\n",
    "        print(f\"‚ö†Ô∏è WARNING: {failed_batches} batches failed in epoch {epoch}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "    accuracy = 100. * correct / total if total > 0 else 0\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, val_loader, criterion, accelerator):\n",
    "    \"\"\"\n",
    "    Enhanced evaluation with comprehensive error handling\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    failed_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(tqdm(val_loader, desc='Evaluating')):\n",
    "            try:\n",
    "                # FIXED: Ensure data and target are on the same device as model\n",
    "                data = data.to(device, non_blocking=True)\n",
    "                target = target.to(device, non_blocking=True)\n",
    "                \n",
    "                # Data validation\n",
    "                if data.isnan().any() or target.isnan().any():\n",
    "                    print(f\"‚ö†Ô∏è WARNING: NaN detected in validation batch {batch_idx}, skipping...\")\n",
    "                    failed_batches += 1\n",
    "                    continue\n",
    "                    \n",
    "                if data.isinf().any() or target.isinf().any():\n",
    "                    print(f\"‚ö†Ô∏è WARNING: Inf detected in validation batch {batch_idx}, skipping...\")\n",
    "                    failed_batches += 1\n",
    "                    continue\n",
    "                \n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                # Check for NaN loss\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"‚ö†Ô∏è WARNING: Invalid loss detected in validation batch {batch_idx}, skipping...\")\n",
    "                    failed_batches += 1\n",
    "                    continue\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "                total += target.size(0)\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e).lower():\n",
    "                    print(f\"üö® CUDA OOM ERROR in validation batch {batch_idx}: {e}\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    failed_batches += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"üö® RUNTIME ERROR in validation batch {batch_idx}: {e}\")\n",
    "                    failed_batches += 1\n",
    "                    continue\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"üö® UNEXPECTED ERROR in validation batch {batch_idx}: {e}\")\n",
    "                failed_batches += 1\n",
    "                continue\n",
    "    \n",
    "    # Report failed batches\n",
    "    if failed_batches > 0:\n",
    "        print(f\"‚ö†Ô∏è WARNING: {failed_batches} validation batches failed\")\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "    accuracy = 100. * correct / total if total > 0 else 0\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, accuracy, filepath):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'accuracy': accuracy,\n",
    "        'config': config\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f'Checkpoint saved: {filepath}')\n",
    "\n",
    "def load_checkpoint(filepath, model, optimizer, scheduler):\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    return checkpoint['epoch'], checkpoint['accuracy']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä LOGGING SETUP BASED ON MODE\n",
    "# =============================================================================\n",
    "\n",
    "if config['wandb_enabled']:\n",
    "    print(\"Initializing Weights & Biases for logging...\")\n",
    "    wandb.init(project=\"imagenet-resnet50\", config=config)\n",
    "else:\n",
    "    print(\"Wandb logging disabled for testing mode\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "# =============================================================================\n",
    "# üöÄ ENHANCED TRAINING LOOP WITH COMPREHENSIVE MONITORING\n",
    "# =============================================================================\n",
    "\n",
    "# Training loop with enhanced monitoring and error handling\n",
    "best_accuracy = 0\n",
    "start_time = time.time()\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"üöÄ Starting enhanced training with comprehensive monitoring...\")\n",
    "print(f\"Target accuracy: {config['target_accuracy']}%\")\n",
    "print(f\"Budget constraint: $25\")\n",
    "print(f\"Training for {config['epochs']} epochs\")\n",
    "print(f\"Early stopping patience: {config.get('early_stopping_patience', 10)}\")\n",
    "\n",
    "# Log training start\n",
    "monitor.logger.info(\"üöÄ TRAINING STARTED\")\n",
    "monitor.logger.info(f\"Target accuracy: {config['target_accuracy']}%\")\n",
    "monitor.logger.info(f\"Total epochs: {config['epochs']}\")\n",
    "monitor.logger.info(f\"Early stopping patience: {config.get('early_stopping_patience', 10)}\")\n",
    "\n",
    "for epoch in range(1, config['epochs'] + 1):\n",
    "    try:\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Log epoch start\n",
    "        monitor.log_epoch_start(epoch, config['epochs'])\n",
    "        \n",
    "        # Train with error handling\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, accelerator, epoch)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Evaluate with error handling\n",
    "        if epoch % config['eval_every'] == 0 or epoch == config['epochs']:\n",
    "            val_loss, val_acc = evaluate(model, val_loader, criterion, accelerator)\n",
    "            \n",
    "            # Log epoch results\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            monitor.log_epoch_end(epoch, train_loss, train_acc, val_loss, val_acc, current_lr, epoch_time)\n",
    "            \n",
    "            print(f'\\nüìä Epoch {epoch} Results:')\n",
    "            print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "            print(f'  Learning Rate: {current_lr:.6f}')\n",
    "            print(f'  Epoch Time: {epoch_time:.2f}s')\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_accuracy:\n",
    "                best_accuracy = val_acc\n",
    "                save_checkpoint(\n",
    "                    model, optimizer, scheduler, epoch, val_acc,\n",
    "                    f'checkpoints/best_model_epoch_{epoch}_acc_{val_acc:.2f}.pth'\n",
    "                )\n",
    "                monitor.logger.info(f\"üèÜ New best model saved with accuracy: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Early stopping check\n",
    "            if early_stopping(val_acc, model):\n",
    "                monitor.logger.info(f\"üõë Early stopping triggered at epoch {epoch}\")\n",
    "                print(f'\\nüõë Early stopping triggered at epoch {epoch}')\n",
    "                print(f'Best accuracy achieved: {best_accuracy:.2f}%')\n",
    "                break\n",
    "            \n",
    "            # Log to wandb (if enabled)\n",
    "            if config['wandb_enabled']:\n",
    "                wandb.log({\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': train_loss,\n",
    "                    'train_acc': train_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_acc': val_acc,\n",
    "                    'learning_rate': current_lr,\n",
    "                    'epoch_time': epoch_time\n",
    "                })\n",
    "        else:\n",
    "            # Log epoch without validation\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            monitor.logger.info(f\"‚úÖ Epoch {epoch} completed in {epoch_time:.2f}s (no validation)\")\n",
    "            print(f'  Epoch time: {epoch_time:.2f}s')\n",
    "        \n",
    "        # Save checkpoint every N epochs\n",
    "        if epoch % config['save_every'] == 0:\n",
    "            save_checkpoint(\n",
    "                model, optimizer, scheduler, epoch, val_acc if 'val_acc' in locals() else 0,\n",
    "                f'checkpoints/checkpoint_epoch_{epoch}.pth'\n",
    "            )\n",
    "            monitor.logger.info(f\"üíæ Checkpoint saved at epoch {epoch}\")\n",
    "        \n",
    "        # Check if we've reached target accuracy\n",
    "        if 'val_acc' in locals() and val_acc >= config['target_accuracy']:\n",
    "            monitor.logger.info(f\"üéâ Target accuracy of {config['target_accuracy']}% reached!\")\n",
    "            print(f'\\nüéâ Target accuracy of {config[\"target_accuracy\"]}% reached! Stopping early.')\n",
    "            break\n",
    "            \n",
    "        # Memory cleanup\n",
    "        if epoch % config.get('memory_cleanup_frequency', 5) == 0:\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "    except Exception as e:\n",
    "        monitor.logger.error(f\"üö® CRITICAL ERROR in epoch {epoch}: {e}\")\n",
    "        print(f'\\nüö® CRITICAL ERROR in epoch {epoch}: {e}')\n",
    "        print(\"Attempting to continue training...\")\n",
    "        \n",
    "        # Try to recover\n",
    "        try:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Continue with next epoch\n",
    "        continue\n",
    "\n",
    "# Training completion\n",
    "total_time = time.time() - start_time\n",
    "monitor.log_training_complete(best_accuracy, total_time)\n",
    "\n",
    "print(f'\\nüéâ Training completed in {total_time/3600:.2f} hours')\n",
    "print(f'Best accuracy: {best_accuracy:.2f}%')\n",
    "\n",
    "# Save final model\n",
    "save_checkpoint(\n",
    "    model, optimizer, scheduler, config['epochs'], best_accuracy,\n",
    "    'checkpoints/final_model.pth'\n",
    ")\n",
    "\n",
    "print(\"üìÑ Training summary and logs saved to 'logs/' directory\")\n",
    "print(\"üöÄ Enhanced training with comprehensive monitoring completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "print(\"\\nFinal evaluation...\")\n",
    "final_loss, final_acc = evaluate(model, val_loader, criterion, accelerator)\n",
    "print(f'Final validation accuracy: {final_acc:.2f}%')\n",
    "print(f'Final validation loss: {final_loss:.4f}')\n",
    "\n",
    "# Test on a few samples\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        if i >= 3:  # Test on first 3 batches\n",
    "            break\n",
    "        \n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        \n",
    "        print(f'\\nBatch {i+1}:')\n",
    "        for j in range(min(5, len(data))):\n",
    "            true_class = train_dataset.classes[target[j].item()]\n",
    "            pred_class = train_dataset.classes[pred[j].item()]\n",
    "            confidence = F.softmax(output[j], dim=0)[pred[j]].item()\n",
    "            \n",
    "            print(f'  True: {true_class}, Pred: {pred_class}, Conf: {confidence:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Estimation and Budget Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost estimation for EC2 training\n",
    "def estimate_training_cost():\n",
    "    # EC2 instance costs (as of 2024)\n",
    "    instance_costs = {\n",
    "        'g4dn.xlarge': 0.526,  # 1 GPU, 4 vCPU, 16 GB RAM\n",
    "        'g4dn.2xlarge': 0.752,  # 1 GPU, 8 vCPU, 32 GB RAM\n",
    "        'g4dn.4xlarge': 1.204,  # 1 GPU, 16 vCPU, 64 GB RAM\n",
    "        'p3.2xlarge': 3.06,     # 1 V100 GPU\n",
    "        'p3.8xlarge': 12.24,    # 4 V100 GPUs\n",
    "    }\n",
    "    \n",
    "    # Estimated training time (hours)\n",
    "    estimated_hours = {\n",
    "        'g4dn.xlarge': 24,      # Slower training\n",
    "        'g4dn.2xlarge': 18,    # Medium speed\n",
    "        'g4dn.4xlarge': 12,    # Faster training\n",
    "        'p3.2xlarge': 8,        # V100 is much faster\n",
    "        'p3.8xlarge': 4,        # Multiple V100s\n",
    "    }\n",
    "    \n",
    "    print(\"EC2 Training Cost Estimation:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for instance_type in instance_costs:\n",
    "        hourly_cost = instance_costs[instance_type]\n",
    "        training_hours = estimated_hours[instance_type]\n",
    "        total_cost = hourly_cost * training_hours\n",
    "        \n",
    "        print(f\"{instance_type:12} | ${hourly_cost:6.3f}/hr | {training_hours:2d}hrs | ${total_cost:6.2f} total\")\n",
    "        \n",
    "        if total_cost <= 25:\n",
    "            print(f\"  ‚úÖ Within budget!\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Over budget\")\n",
    "    \n",
    "    print(\"\\nRecommended for $25 budget:\")\n",
    "    print(\"1. g4dn.2xlarge (18 hours) - $13.54\")\n",
    "    print(\"2. g4dn.4xlarge (12 hours) - $14.45\")\n",
    "    print(\"3. p3.2xlarge (8 hours) - $24.48\")\n",
    "    \n",
    "    print(\"\\nOptimization strategies:\")\n",
    "    print(\"- Use mixed precision training (fp16)\")\n",
    "    print(\"- Implement gradient accumulation\")\n",
    "    print(\"- Use efficient data loading\")\n",
    "    print(\"- Early stopping when target accuracy reached\")\n",
    "    print(\"- Use smaller batch sizes if memory constrained\")\n",
    "\n",
    "estimate_training_cost()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
